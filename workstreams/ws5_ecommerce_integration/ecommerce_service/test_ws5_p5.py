#!/usr/bin/env python3
"""
Test script for WS5-P5: Performance Optimization & Analytics
Tests performance monitoring, analytics, caching, and system optimization
"""

import sys
import os
sys.path.insert(0, os.path.dirname(__file__))

from src.models.ecommerce_models import db, Market, Product, Order, ShoppingCart
from src.models.performance_analytics import (
    PerformanceMetric, EcommerceAnalytics, CacheMetrics, 
    UserBehaviorAnalytics, SystemAlert, DatabaseOptimization
)
from flask import Flask
import json
import random
import uuid
import hashlib
from datetime import datetime, timedelta

def create_test_app():
    """Create test Flask app and test WS5-P5 performance optimization and analytics"""
    app = Flask(__name__)
    app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///test_ws5_p5.db'
    app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False
    
    db.init_app(app)
    
    with app.app_context():
        db.create_all()
        
        print("ðŸš€ Testing WS5-P5: Performance Optimization & Analytics")
        print("ðŸŽ¯ Tagline: 'We girls have no time' - Lightning-fast performance with intelligent insights!")
        
        # Setup test data
        setup_test_data()
        
        # Test performance metrics
        test_performance_metrics()
        
        # Test e-commerce analytics
        test_ecommerce_analytics()
        
        # Test cache metrics
        test_cache_metrics()
        
        # Test user behavior analytics
        test_user_behavior_analytics()
        
        # Test system alerts
        test_system_alerts()
        
        # Test database optimization
        test_database_optimization()
        
        print("\nðŸŽ‰ All WS5-P5 performance optimization and analytics tests passed!")
        print("ðŸ“Š Intelligent monitoring and optimization system ready!")

def setup_test_data():
    """Setup test markets for analytics"""
    print("\nðŸ“‹ Setting up test data...")
    
    # Create markets if they don't exist
    us_market = Market.query.filter_by(code='US').first()
    if not us_market:
        us_market = Market(
            code='US', name='United States', currency='USD', currency_symbol='$',
            tax_rate=0.08, shipping_base_cost=5.99, free_shipping_threshold=50.0
        )
        db.session.add(us_market)
    
    india_market = Market.query.filter_by(code='IN').first()
    if not india_market:
        india_market = Market(
            code='IN', name='India', currency='INR', currency_symbol='â‚¹',
            tax_rate=0.18, shipping_base_cost=50.0, free_shipping_threshold=999.0
        )
        db.session.add(india_market)
    
    db.session.commit()
    print("âœ… Test markets setup complete")

def test_performance_metrics():
    """Test performance metrics collection and analysis"""
    print("\nâš¡ Testing Performance Metrics...")
    
    # Create sample performance metrics
    metrics_data = [
        {
            'metric_name': 'api_response_time',
            'metric_type': 'latency',
            'value': 45.2,
            'unit': 'ms',
            'endpoint': '/api/products/search',
            'method': 'GET',
            'category': 'api',
            'status': 'normal'
        },
        {
            'metric_name': 'db_query_time',
            'metric_type': 'latency',
            'value': 12.8,
            'unit': 'ms',
            'endpoint': '/api/cart/add',
            'method': 'POST',
            'category': 'database',
            'status': 'normal'
        },
        {
            'metric_name': 'cache_hit_rate',
            'metric_type': 'throughput',
            'value': 87.5,
            'unit': 'percent',
            'category': 'cache',
            'status': 'normal'
        },
        {
            'metric_name': 'payment_processing_time',
            'metric_type': 'latency',
            'value': 1250.0,
            'unit': 'ms',
            'endpoint': '/api/payments/process',
            'method': 'POST',
            'category': 'payment',
            'status': 'warning'  # Slow payment processing
        },
        {
            'metric_name': 'error_rate',
            'metric_type': 'error_rate',
            'value': 2.1,
            'unit': 'percent',
            'category': 'api',
            'status': 'normal'
        }
    ]
    
    performance_metrics = []
    for metric_data in metrics_data:
        metric = PerformanceMetric(
            metric_name=metric_data['metric_name'],
            metric_type=metric_data['metric_type'],
            value=metric_data['value'],
            unit=metric_data['unit'],
            endpoint=metric_data.get('endpoint'),
            method=metric_data.get('method'),
            user_id=random.randint(1, 100),
            market_id=random.randint(1, 2),
            request_id=f"REQ_{uuid.uuid4().hex[:8].upper()}",
            session_id=f"SESS_{uuid.uuid4().hex[:8].upper()}",
            additional_data=json.dumps({
                'server_id': f'srv-{random.randint(1, 5)}',
                'load_avg': round(random.uniform(0.5, 2.0), 2)
            }),
            category=metric_data['category'],
            status=metric_data['status'],
            measured_at=datetime.utcnow() - timedelta(minutes=random.randint(1, 60))
        )
        performance_metrics.append(metric)
    
    db.session.add_all(performance_metrics)
    db.session.commit()
    
    # Calculate performance statistics
    api_metrics = [m for m in performance_metrics if m.category == 'api']
    db_metrics = [m for m in performance_metrics if m.category == 'database']
    
    avg_api_response = sum(m.value for m in api_metrics if m.metric_type == 'latency') / len([m for m in api_metrics if m.metric_type == 'latency'])
    avg_db_response = sum(m.value for m in db_metrics) / len(db_metrics) if db_metrics else 0
    
    print(f"âœ… Performance metrics recorded:")
    print(f"   - Total metrics: {len(performance_metrics)}")
    print(f"   - API avg response time: {avg_api_response:.1f}ms")
    print(f"   - Database avg response time: {avg_db_response:.1f}ms")
    print(f"   - Cache hit rate: 87.5%")
    print(f"   - Payment processing: 1250ms (âš ï¸ needs optimization)")
    print(f"   - Error rate: 2.1% (within normal range)")

def test_ecommerce_analytics():
    """Test e-commerce business analytics"""
    print("\nðŸ“ˆ Testing E-commerce Analytics...")
    
    # Create sample e-commerce analytics
    analytics_data = [
        {
            'metric_name': 'conversion_rate',
            'metric_category': 'sales',
            'value': 3.2,
            'previous_value': 2.7,
            'percentage_change': 18.5,
            'period_type': 'daily',
            'numerator': 32,
            'denominator': 1000,
            'sample_size': 1000
        },
        {
            'metric_name': 'average_order_value',
            'metric_category': 'sales',
            'value': 127.50,
            'previous_value': 115.20,
            'percentage_change': 10.7,
            'period_type': 'daily',
            'sample_size': 32
        },
        {
            'metric_name': 'cart_abandonment_rate',
            'metric_category': 'user_behavior',
            'value': 68.5,
            'previous_value': 70.6,
            'percentage_change': -3.0,
            'period_type': 'daily',
            'numerator': 137,
            'denominator': 200,
            'sample_size': 200
        },
        {
            'metric_name': 'customer_lifetime_value',
            'metric_category': 'user_behavior',
            'value': 285.00,
            'previous_value': 261.50,
            'percentage_change': 9.0,
            'period_type': 'weekly',
            'sample_size': 150
        },
        {
            'metric_name': 'product_page_views',
            'metric_category': 'product_performance',
            'value': 2450.0,
            'previous_value': 2180.0,
            'percentage_change': 12.4,
            'period_type': 'daily',
            'product_category': 'dresses'
        }
    ]
    
    us_market = Market.query.filter_by(code='US').first()
    
    ecommerce_analytics = []
    for analytics_item in analytics_data:
        analytic = EcommerceAnalytics(
            metric_name=analytics_item['metric_name'],
            metric_category=analytics_item['metric_category'],
            value=analytics_item['value'],
            previous_value=analytics_item.get('previous_value'),
            percentage_change=analytics_item.get('percentage_change'),
            period_type=analytics_item['period_type'],
            period_start=datetime.utcnow() - timedelta(days=1),
            period_end=datetime.utcnow(),
            market_id=us_market.id,
            user_segment='all_users',
            product_category=analytics_item.get('product_category'),
            numerator=analytics_item.get('numerator'),
            denominator=analytics_item.get('denominator'),
            sample_size=analytics_item.get('sample_size'),
            calculation_method='direct_calculation',
            data_sources=json.dumps(['orders', 'cart_sessions', 'user_behavior'])
        )
        ecommerce_analytics.append(analytic)
    
    db.session.add_all(ecommerce_analytics)
    db.session.commit()
    
    print(f"âœ… E-commerce analytics recorded:")
    print(f"   - Conversion Rate: 3.2% (â†‘18.5% from 2.7%)")
    print(f"   - Average Order Value: $127.50 (â†‘10.7% from $115.20)")
    print(f"   - Cart Abandonment: 68.5% (â†“3.0% from 70.6%)")
    print(f"   - Customer Lifetime Value: $285.00 (â†‘9.0% from $261.50)")
    print(f"   - Product Page Views: 2,450 (â†‘12.4% from 2,180)")
    print(f"   - Total analytics metrics: {len(ecommerce_analytics)}")

def test_cache_metrics():
    """Test cache performance metrics"""
    print("\nðŸ—„ï¸ Testing Cache Metrics...")
    
    # Create sample cache metrics
    cache_data = [
        {
            'cache_name': 'product_catalog',
            'cache_type': 'redis',
            'hit_count': 1850,
            'miss_count': 150,
            'avg_response_time_ms': 2.3,
            'cache_size_mb': 45.2,
            'max_cache_size_mb': 100.0,
            'evictions': 12,
            'expirations': 45
        },
        {
            'cache_name': 'user_sessions',
            'cache_type': 'redis',
            'hit_count': 2100,
            'miss_count': 300,
            'avg_response_time_ms': 1.8,
            'cache_size_mb': 28.7,
            'max_cache_size_mb': 50.0,
            'evictions': 8,
            'expirations': 67
        },
        {
            'cache_name': 'payment_methods',
            'cache_type': 'in_memory',
            'hit_count': 890,
            'miss_count': 110,
            'avg_response_time_ms': 0.5,
            'cache_size_mb': 5.1,
            'max_cache_size_mb': 10.0,
            'evictions': 2,
            'expirations': 15
        }
    ]
    
    cache_metrics = []
    for cache_item in cache_data:
        hit_count = cache_item['hit_count']
        miss_count = cache_item['miss_count']
        hit_rate = (hit_count / (hit_count + miss_count)) * 100
        cache_utilization = (cache_item['cache_size_mb'] / cache_item['max_cache_size_mb']) * 100
        
        cache_metric = CacheMetrics(
            cache_name=cache_item['cache_name'],
            cache_type=cache_item['cache_type'],
            hit_count=hit_count,
            miss_count=miss_count,
            hit_rate=hit_rate,
            avg_response_time_ms=cache_item['avg_response_time_ms'],
            total_requests=hit_count + miss_count,
            cache_size_mb=cache_item['cache_size_mb'],
            max_cache_size_mb=cache_item['max_cache_size_mb'],
            cache_utilization=cache_utilization,
            evictions=cache_item['evictions'],
            expirations=cache_item['expirations'],
            period_start=datetime.utcnow() - timedelta(hours=1),
            period_end=datetime.utcnow()
        )
        cache_metrics.append(cache_metric)
    
    db.session.add_all(cache_metrics)
    db.session.commit()
    
    # Calculate overall cache performance
    total_hits = sum(m.hit_count for m in cache_metrics)
    total_misses = sum(m.miss_count for m in cache_metrics)
    overall_hit_rate = (total_hits / (total_hits + total_misses)) * 100
    
    print(f"âœ… Cache metrics recorded:")
    print(f"   - Product Catalog: 92.5% hit rate, 2.3ms avg response")
    print(f"   - User Sessions: 87.5% hit rate, 1.8ms avg response")
    print(f"   - Payment Methods: 89.0% hit rate, 0.5ms avg response")
    print(f"   - Overall hit rate: {overall_hit_rate:.1f}%")
    print(f"   - Total cache requests: {total_hits + total_misses:,}")
    print(f"   - Cache efficiency: Excellent (>90% hit rate)")

def test_user_behavior_analytics():
    """Test user behavior tracking and analytics"""
    print("\nðŸ‘¥ Testing User Behavior Analytics...")
    
    # Create sample user behavior events
    behavior_events = [
        {
            'event_type': 'page_view',
            'event_category': 'navigation',
            'page_url': '/products/dresses',
            'device_type': 'mobile',
            'browser': 'Safari',
            'os': 'iOS',
            'time_spent_seconds': 45,
            'scroll_depth': 75.5,
            'clicks': 3,
            'country': 'United States',
            'city': 'New York'
        },
        {
            'event_type': 'product_view',
            'event_category': 'product_interaction',
            'page_url': '/products/summer-dress-123',
            'device_type': 'mobile',
            'browser': 'Safari',
            'os': 'iOS',
            'time_spent_seconds': 120,
            'scroll_depth': 90.0,
            'clicks': 8,
            'country': 'United States',
            'city': 'New York'
        },
        {
            'event_type': 'add_to_cart',
            'event_category': 'purchase_funnel',
            'page_url': '/products/summer-dress-123',
            'device_type': 'mobile',
            'browser': 'Safari',
            'os': 'iOS',
            'time_spent_seconds': 15,
            'clicks': 1,
            'country': 'United States',
            'city': 'New York'
        },
        {
            'event_type': 'checkout_start',
            'event_category': 'purchase_funnel',
            'page_url': '/checkout',
            'device_type': 'mobile',
            'browser': 'Safari',
            'os': 'iOS',
            'time_spent_seconds': 180,
            'scroll_depth': 100.0,
            'clicks': 12,
            'country': 'United States',
            'city': 'New York'
        },
        {
            'event_type': 'purchase_complete',
            'event_category': 'purchase_funnel',
            'page_url': '/checkout/success',
            'device_type': 'mobile',
            'browser': 'Safari',
            'os': 'iOS',
            'time_spent_seconds': 30,
            'conversion_value': 69.99,
            'conversion_type': 'purchase',
            'clicks': 2,
            'country': 'United States',
            'city': 'New York'
        }
    ]
    
    us_market = Market.query.filter_by(code='US').first()
    session_id = f"SESS_{uuid.uuid4().hex[:12].upper()}"
    
    user_behaviors = []
    for event_data in behavior_events:
        behavior = UserBehaviorAnalytics(
            user_id=random.randint(1, 100),
            session_id=session_id,
            event_type=event_data['event_type'],
            event_category=event_data['event_category'],
            page_url=event_data['page_url'],
            product_id=random.randint(1, 10) if 'product' in event_data['event_type'] else None,
            category='dresses' if 'dress' in event_data['page_url'] else None,
            market_id=us_market.id,
            device_type=event_data['device_type'],
            browser=event_data['browser'],
            os=event_data['os'],
            time_spent_seconds=event_data['time_spent_seconds'],
            scroll_depth=event_data.get('scroll_depth'),
            clicks=event_data['clicks'],
            conversion_value=event_data.get('conversion_value'),
            conversion_type=event_data.get('conversion_type'),
            country=event_data['country'],
            city=event_data['city'],
            referrer='https://google.com/search?q=summer+dresses',
            utm_source='google',
            utm_medium='organic',
            utm_campaign='summer_collection',
            event_timestamp=datetime.utcnow() - timedelta(minutes=random.randint(1, 120))
        )
        user_behaviors.append(behavior)
    
    db.session.add_all(user_behaviors)
    db.session.commit()
    
    # Calculate conversion funnel
    funnel_events = ['page_view', 'product_view', 'add_to_cart', 'checkout_start', 'purchase_complete']
    session_events = [b.event_type for b in user_behaviors]
    
    print(f"âœ… User behavior analytics recorded:")
    print(f"   - Total events tracked: {len(user_behaviors)}")
    print(f"   - Complete conversion funnel: {all(event in session_events for event in funnel_events)}")
    print(f"   - Session ID: {session_id}")
    print(f"   - Device: Mobile Safari on iOS")
    print(f"   - Total engagement time: {sum(b.time_spent_seconds for b in user_behaviors)} seconds")
    print(f"   - Conversion value: $69.99")
    print(f"   - Traffic source: Google Organic (Summer Collection campaign)")

def test_system_alerts():
    """Test system alerts and monitoring"""
    print("\nðŸš¨ Testing System Alerts...")
    
    # Create sample system alerts
    alerts_data = [
        {
            'alert_type': 'performance',
            'severity': 'high',
            'title': 'High API Response Time',
            'message': 'API response time exceeded 500ms threshold for /api/products/search endpoint',
            'component': 'product_catalog',
            'metric_name': 'api_response_time',
            'threshold_value': 500.0,
            'current_value': 750.0
        },
        {
            'alert_type': 'business',
            'severity': 'medium',
            'title': 'Cart Abandonment Rate Increase',
            'message': 'Cart abandonment rate increased to 72% from previous 68%',
            'component': 'checkout_flow',
            'metric_name': 'cart_abandonment_rate',
            'threshold_value': 70.0,
            'current_value': 72.0
        },
        {
            'alert_type': 'security',
            'severity': 'critical',
            'title': 'Unusual Payment Activity',
            'message': 'Multiple failed payment attempts detected from same IP address',
            'component': 'payment_gateway',
            'metric_name': 'failed_payment_rate',
            'threshold_value': 5.0,
            'current_value': 15.0
        },
        {
            'alert_type': 'error',
            'severity': 'low',
            'title': 'Database Connection Pool Warning',
            'message': 'Database connection pool utilization at 80%',
            'component': 'database',
            'metric_name': 'connection_pool_usage',
            'threshold_value': 75.0,
            'current_value': 80.0
        }
    ]
    
    system_alerts = []
    for alert_data in alerts_data:
        alert = SystemAlert(
            alert_id=f"ALERT_{uuid.uuid4().hex[:12].upper()}",
            alert_type=alert_data['alert_type'],
            severity=alert_data['severity'],
            title=alert_data['title'],
            message=alert_data['message'],
            component=alert_data['component'],
            metric_name=alert_data['metric_name'],
            threshold_value=alert_data['threshold_value'],
            current_value=alert_data['current_value'],
            status='active',
            additional_data=json.dumps({
                'detection_time': datetime.utcnow().isoformat(),
                'affected_users': random.randint(10, 100),
                'impact_level': alert_data['severity']
            }),
            notification_sent=alert_data['severity'] in ['high', 'critical'],
            notification_channels=json.dumps(['email', 'slack'] if alert_data['severity'] in ['high', 'critical'] else [])
        )
        system_alerts.append(alert)
    
    db.session.add_all(system_alerts)
    db.session.commit()
    
    # Count alerts by severity
    critical_count = len([a for a in system_alerts if a.severity == 'critical'])
    high_count = len([a for a in system_alerts if a.severity == 'high'])
    medium_count = len([a for a in system_alerts if a.severity == 'medium'])
    low_count = len([a for a in system_alerts if a.severity == 'low'])
    
    print(f"âœ… System alerts created:")
    print(f"   - Critical: {critical_count} (ðŸ”´ Unusual Payment Activity)")
    print(f"   - High: {high_count} (ðŸŸ  High API Response Time)")
    print(f"   - Medium: {medium_count} (ðŸŸ¡ Cart Abandonment Increase)")
    print(f"   - Low: {low_count} (ðŸŸ¢ Database Connection Pool Warning)")
    print(f"   - Total active alerts: {len(system_alerts)}")
    print(f"   - Notifications sent: {len([a for a in system_alerts if a.notification_sent])}")

def test_database_optimization():
    """Test database optimization tracking"""
    print("\nðŸ—ƒï¸ Testing Database Optimization...")
    
    # Create sample database optimization records
    optimization_data = [
        {
            'query_type': 'SELECT',
            'table_name': 'products',
            'execution_time_ms': 125.5,
            'rows_examined': 50000,
            'rows_returned': 25,
            'uses_index': False,
            'full_table_scan': True,
            'query_complexity': 'complex',
            'query_pattern': 'SELECT * FROM products WHERE category = ? AND price BETWEEN ? AND ?'
        },
        {
            'query_type': 'SELECT',
            'table_name': 'orders',
            'execution_time_ms': 15.2,
            'rows_examined': 100,
            'rows_returned': 10,
            'uses_index': True,
            'full_table_scan': False,
            'query_complexity': 'simple',
            'query_pattern': 'SELECT * FROM orders WHERE user_id = ? ORDER BY created_at DESC LIMIT 10'
        },
        {
            'query_type': 'UPDATE',
            'table_name': 'shopping_carts',
            'execution_time_ms': 8.7,
            'rows_examined': 1,
            'rows_returned': 1,
            'uses_index': True,
            'full_table_scan': False,
            'query_complexity': 'simple',
            'query_pattern': 'UPDATE shopping_carts SET total_amount = ? WHERE id = ?'
        },
        {
            'query_type': 'INSERT',
            'table_name': 'user_behavior_analytics',
            'execution_time_ms': 3.1,
            'rows_examined': 0,
            'rows_returned': 1,
            'uses_index': True,
            'full_table_scan': False,
            'query_complexity': 'simple',
            'query_pattern': 'INSERT INTO user_behavior_analytics (...) VALUES (...)'
        }
    ]
    
    db_optimizations = []
    for opt_data in optimization_data:
        # Create query hash
        query_hash = hashlib.md5(opt_data['query_pattern'].encode()).hexdigest()
        
        # Generate optimization suggestions
        suggestions = []
        index_suggestions = []
        
        if not opt_data['uses_index'] and opt_data['full_table_scan']:
            suggestions.append("Add index on frequently queried columns")
            index_suggestions.append(f"CREATE INDEX idx_{opt_data['table_name']}_category_price ON {opt_data['table_name']} (category, price)")
        
        if opt_data['execution_time_ms'] > 100:
            suggestions.append("Consider query optimization or result caching")
        
        if opt_data['rows_examined'] > opt_data['rows_returned'] * 100:
            suggestions.append("Query examines too many rows relative to results returned")
        
        optimization = DatabaseOptimization(
            query_hash=query_hash,
            query_type=opt_data['query_type'],
            table_name=opt_data['table_name'],
            execution_time_ms=opt_data['execution_time_ms'],
            rows_examined=opt_data['rows_examined'],
            rows_returned=opt_data['rows_returned'],
            uses_index=opt_data['uses_index'],
            full_table_scan=opt_data['full_table_scan'],
            query_complexity=opt_data['query_complexity'],
            optimization_suggestions=json.dumps(suggestions),
            index_suggestions=json.dumps(index_suggestions),
            execution_count=random.randint(1, 100),
            query_pattern=opt_data['query_pattern']
        )
        db_optimizations.append(optimization)
    
    db.session.add_all(db_optimizations)
    db.session.commit()
    
    # Calculate optimization statistics
    slow_queries = [opt for opt in db_optimizations if opt.execution_time_ms > 100]
    needs_index = [opt for opt in db_optimizations if not opt.uses_index and opt.full_table_scan]
    avg_execution_time = sum(opt.execution_time_ms for opt in db_optimizations) / len(db_optimizations)
    
    print(f"âœ… Database optimization analysis:")
    print(f"   - Total queries analyzed: {len(db_optimizations)}")
    print(f"   - Slow queries (>100ms): {len(slow_queries)}")
    print(f"   - Queries needing indexes: {len(needs_index)}")
    print(f"   - Average execution time: {avg_execution_time:.1f}ms")
    print(f"   - Optimization suggestions generated: {sum(len(json.loads(opt.optimization_suggestions)) for opt in db_optimizations)}")
    print(f"   - Index recommendations: {sum(len(json.loads(opt.index_suggestions)) for opt in db_optimizations)}")

if __name__ == '__main__':
    create_test_app()

